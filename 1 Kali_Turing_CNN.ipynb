{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEzyV3C7Zw5G"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "!curl -L -o archive.zip\\\n",
        "https://www.kaggle.com/api/v1/datasets/download/kaustubhb999/tomatoleaf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U50RjIh1aU5B",
        "outputId": "d6ae258b-b112-4b17-b0c3-42e02e274fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  archive.zip\n",
            "replace tomato/cnn_train.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Step 1) Dataset preparation\n",
        "train_path = '/content/tomato/train'\n",
        "test_path = '/content/tomato/val'\n",
        "# 1) resize the image to 256x256\n",
        "#torchvision.transforms.Resize(256,256),\n",
        "\n",
        "# 2) convert input image to tensor\n",
        "#torchvision.transforms.ToTensor(),\n",
        "\n",
        "# 3) normalize the image\n",
        "#torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
        "\n",
        "# create an empty list\n",
        "transform = [torchvision.transforms.Resize((256,256)),\n",
        " torchvision.transforms.ToTensor(),\n",
        " torchvision.transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])]\n",
        "\n",
        "transformation = torchvision.transforms.Compose(transform)\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_path,\n",
        "                                                transform=transformation)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=test_path,\n",
        "                                                transform=transformation)\n",
        "\n",
        "# split into training and testing dataset\n",
        "# train_size = int(0.7*len(full_dataset))# 70% of data will be trained\n",
        "# test_size = len(full_dataset) - train_size # 30% of data will be test\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(full_dataset,[train_size,test_size])"
      ],
      "metadata": {
        "id": "pBXEw-IUaYga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "hLmpVSe6bcy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up your data loader\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "num_classes = 3\n",
        "learning_rate = 0.001\n",
        "num_classes = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train loader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True) # shuffle so AI learn\n",
        "\n",
        "# Test loader\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "h7GG-W8SbiW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3) Create CNN model\n",
        "import torch\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # First conv layer\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch1 = torch.nn.BatchNorm2d(8)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Second conv layer\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch2 = torch.nn.BatchNorm2d(16)\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Third conv layer\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch3 = torch.nn.BatchNorm2d(32)\n",
        "        self.act3 = torch.nn.ReLU()\n",
        "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fourth conv layer\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch4 = torch.nn.BatchNorm2d(64)\n",
        "        self.act4 = torch.nn.ReLU()\n",
        "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fifth conv layer\n",
        "        self.conv5 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batch5 = torch.nn.BatchNorm2d(128)\n",
        "        self.act5 = torch.nn.ReLU()\n",
        "        self.pool5 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Flatten\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = torch.nn.Linear(128 * 8 * 8, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First conv layer\n",
        "        out = self.conv1(x)\n",
        "        out = self.batch1(out)\n",
        "        out = self.act1(out)\n",
        "        out = self.pool1(out)\n",
        "\n",
        "        # Second conv layer\n",
        "        out = self.conv2(out)\n",
        "        out = self.batch2(out)\n",
        "        out = self.act2(out)\n",
        "        out = self.pool2(out)\n",
        "\n",
        "        # Third conv layer\n",
        "        out = self.conv3(out)\n",
        "        out = self.batch3(out)\n",
        "        out = self.act3(out)\n",
        "        out = self.pool3(out)\n",
        "\n",
        "        # Fourth conv layer\n",
        "        out = self.conv4(out)\n",
        "        out = self.batch4(out)\n",
        "        out = self.act4(out)\n",
        "        out = self.pool4(out)\n",
        "\n",
        "        # Fifth conv layer\n",
        "        out = self.conv5(out)\n",
        "        out = self.batch5(out)\n",
        "        out = self.act5(out)\n",
        "        out = self.pool5(out)\n",
        "\n",
        "        # Flatten\n",
        "        out = self.flatten(out)\n",
        "\n",
        "        # Fully connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return torch.nn.functional.log_softmax(out, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "model = CNN(num_classes).to(device)\n",
        "from torchsummary import summary\n",
        "\n",
        "# Create the model instance\n",
        "model = CNN(num_classes=10).to('cuda')  # Use 'cuda' if GPU is available, or 'cpu' otherwise\n",
        "\n",
        "# Call the summary function\n",
        "summary(model, input_size=(3, 256, 256))  # Adjust input_size based on your model\n"
      ],
      "metadata": {
        "id": "PBo-r898bp2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "def test(model,test_loader,device):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "      images = images.to(device) # x is already has the batch size of 100\n",
        "      labels = labels.to(device)\n",
        "      predicted_output = model(images)\n",
        "      _, predicted = torch.max(predicted_output.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  acc = correct/total*100\n",
        "\n",
        "  return acc\n",
        "\n",
        "# loss\n",
        "creiterion = torch.nn.CrossEntropyLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#Train the model\n",
        "#Set the model into training mode\n",
        "epoch_loss = 0\n",
        "loss_list = [] #to store the losses in list iteration\n",
        "training_loss = [] # to store the epoch training loss\n",
        "training_acc = [] # to store training accuracy\n",
        "epoch_num = [] # to store num of epoch\n",
        "\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "    # lets say i am using GPU, this will allow the gpu to process the data\n",
        "    model.train()\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #label = torch.eye(num_classes)[labels].to(device)\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(images)\n",
        "    loss = creiterion(outputs, labels)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # to calculate the loss\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "    loss_list.append(epoch_loss)\n",
        "\n",
        "    # to print out the loss for every step\n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Epoch[{}/{}],Step [{}/{}],Loss{:.4f}'.format(epoch+1,num_epochs,i+1,len(train_loader),loss.item()))\n",
        "\n",
        "  # training loss\n",
        "  avg_loss = epoch_loss/(i+1)\n",
        "  training_loss.append(avg_loss)\n",
        "\n",
        "\n",
        "  #accuracy\n",
        "  accuracy = test(model,test_loader,device)\n",
        "  training_acc.append(accuracy)\n",
        "\n",
        "  epoch_num.append(epoch)\n",
        "  epoch_loss = 0"
      ],
      "metadata": {
        "id": "AjRzgvibcTia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3) Model evaluation\n",
        "\n",
        "# plot the graph\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_num,training_acc)\n",
        "plt.show()\n",
        "\n",
        "# classification report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for images, labels in test_loader:\n",
        "  images = images.to(device)  # Move images to the same device as the model\n",
        "  predicted_output = model(images)# input into model becomes images\n",
        "  _, predicted = torch.max(predicted_output.data, 1)\n",
        "  y_pred.extend(predicted.data.cpu().numpy())\n",
        "\n",
        "  labels = labels.data.cpu().numpy()\n",
        "  y_true.extend(labels)\n",
        "\n",
        "# confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(cf_matrix)\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "EhuyjRXrf8ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss_list)\n",
        "\n",
        "plt.plot(training_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLs7_Kq-mtuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), 'Kali Turing_CNN.pt')"
      ],
      "metadata": {
        "id": "BRY6Gjt4AF74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}